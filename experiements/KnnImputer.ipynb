{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuananle/.zshenv:.:2: no such file or directory: /home/xuananle/.cargo/env\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Requirement '/kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install /kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import polars as pl\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.base import clone, BaseEstimator, RegressorMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import optuna\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from colorama import Fore, Style\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "n_splits = 5\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return seed\n",
    "\n",
    "# Set seed\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>Physical-Diastolic_BP</th>\n",
       "      <th>Physical-HeartRate</th>\n",
       "      <th>Physical-Systolic_BP</th>\n",
       "      <th>Fitness_Endurance-Max_Stage</th>\n",
       "      <th>Fitness_Endurance-Time_Mins</th>\n",
       "      <th>Fitness_Endurance-Time_Sec</th>\n",
       "      <th>FGC-FGC_CU</th>\n",
       "      <th>FGC-FGC_CU_Zone</th>\n",
       "      <th>FGC-FGC_GSND</th>\n",
       "      <th>FGC-FGC_GSND_Zone</th>\n",
       "      <th>FGC-FGC_GSD</th>\n",
       "      <th>FGC-FGC_GSD_Zone</th>\n",
       "      <th>FGC-FGC_PU</th>\n",
       "      <th>FGC-FGC_PU_Zone</th>\n",
       "      <th>FGC-FGC_SRL</th>\n",
       "      <th>FGC-FGC_SRL_Zone</th>\n",
       "      <th>FGC-FGC_SRR</th>\n",
       "      <th>FGC-FGC_SRR_Zone</th>\n",
       "      <th>FGC-FGC_TL</th>\n",
       "      <th>FGC-FGC_TL_Zone</th>\n",
       "      <th>BIA-BIA_Activity_Level_num</th>\n",
       "      <th>BIA-BIA_BMC</th>\n",
       "      <th>BIA-BIA_BMI</th>\n",
       "      <th>BIA-BIA_BMR</th>\n",
       "      <th>BIA-BIA_DEE</th>\n",
       "      <th>BIA-BIA_ECW</th>\n",
       "      <th>BIA-BIA_FFM</th>\n",
       "      <th>BIA-BIA_FFMI</th>\n",
       "      <th>BIA-BIA_FMI</th>\n",
       "      <th>BIA-BIA_Fat</th>\n",
       "      <th>BIA-BIA_Frame_num</th>\n",
       "      <th>BIA-BIA_ICW</th>\n",
       "      <th>BIA-BIA_LDM</th>\n",
       "      <th>BIA-BIA_LST</th>\n",
       "      <th>BIA-BIA_SMM</th>\n",
       "      <th>BIA-BIA_TBW</th>\n",
       "      <th>PAQ_A-PAQ_A_Total</th>\n",
       "      <th>PAQ_C-PAQ_C_Total</th>\n",
       "      <th>PCIAT-PCIAT_01</th>\n",
       "      <th>PCIAT-PCIAT_02</th>\n",
       "      <th>PCIAT-PCIAT_03</th>\n",
       "      <th>PCIAT-PCIAT_04</th>\n",
       "      <th>PCIAT-PCIAT_05</th>\n",
       "      <th>PCIAT-PCIAT_06</th>\n",
       "      <th>PCIAT-PCIAT_07</th>\n",
       "      <th>PCIAT-PCIAT_08</th>\n",
       "      <th>PCIAT-PCIAT_09</th>\n",
       "      <th>PCIAT-PCIAT_10</th>\n",
       "      <th>PCIAT-PCIAT_11</th>\n",
       "      <th>PCIAT-PCIAT_12</th>\n",
       "      <th>PCIAT-PCIAT_13</th>\n",
       "      <th>PCIAT-PCIAT_14</th>\n",
       "      <th>PCIAT-PCIAT_15</th>\n",
       "      <th>PCIAT-PCIAT_16</th>\n",
       "      <th>PCIAT-PCIAT_17</th>\n",
       "      <th>PCIAT-PCIAT_18</th>\n",
       "      <th>PCIAT-PCIAT_19</th>\n",
       "      <th>PCIAT-PCIAT_20</th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3960.000000</td>\n",
       "      <td>3960.000000</td>\n",
       "      <td>2421.000000</td>\n",
       "      <td>3022.000000</td>\n",
       "      <td>3027.000000</td>\n",
       "      <td>3076.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>2954.000000</td>\n",
       "      <td>2967.000000</td>\n",
       "      <td>2954.000000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2282.000000</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>1062.000000</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>2310.000000</td>\n",
       "      <td>2271.000000</td>\n",
       "      <td>2305.000000</td>\n",
       "      <td>2267.000000</td>\n",
       "      <td>2307.000000</td>\n",
       "      <td>2269.000000</td>\n",
       "      <td>2324.000000</td>\n",
       "      <td>2285.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.00000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>1721.000000</td>\n",
       "      <td>2733.000000</td>\n",
       "      <td>2734.000000</td>\n",
       "      <td>2731.000000</td>\n",
       "      <td>2731.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2732.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2733.000000</td>\n",
       "      <td>2734.000000</td>\n",
       "      <td>2731.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2732.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2728.000000</td>\n",
       "      <td>2725.000000</td>\n",
       "      <td>2728.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2733.000000</td>\n",
       "      <td>2736.000000</td>\n",
       "      <td>2609.000000</td>\n",
       "      <td>2606.000000</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>2736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.433586</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>65.454771</td>\n",
       "      <td>19.331929</td>\n",
       "      <td>55.946713</td>\n",
       "      <td>89.038615</td>\n",
       "      <td>27.278508</td>\n",
       "      <td>69.648951</td>\n",
       "      <td>81.597236</td>\n",
       "      <td>116.983074</td>\n",
       "      <td>4.989233</td>\n",
       "      <td>7.370270</td>\n",
       "      <td>27.581081</td>\n",
       "      <td>11.259690</td>\n",
       "      <td>0.476337</td>\n",
       "      <td>22.420438</td>\n",
       "      <td>1.829567</td>\n",
       "      <td>23.518622</td>\n",
       "      <td>1.904045</td>\n",
       "      <td>5.579654</td>\n",
       "      <td>0.330251</td>\n",
       "      <td>8.694924</td>\n",
       "      <td>0.618880</td>\n",
       "      <td>8.805635</td>\n",
       "      <td>0.620097</td>\n",
       "      <td>9.252775</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>2.651431</td>\n",
       "      <td>6.719826</td>\n",
       "      <td>19.367048</td>\n",
       "      <td>1237.018187</td>\n",
       "      <td>2064.693747</td>\n",
       "      <td>20.825346</td>\n",
       "      <td>74.021708</td>\n",
       "      <td>15.030554</td>\n",
       "      <td>4.336495</td>\n",
       "      <td>16.855020</td>\n",
       "      <td>1.745354</td>\n",
       "      <td>33.173380</td>\n",
       "      <td>20.02299</td>\n",
       "      <td>67.301883</td>\n",
       "      <td>34.389466</td>\n",
       "      <td>53.998726</td>\n",
       "      <td>2.178853</td>\n",
       "      <td>2.589550</td>\n",
       "      <td>2.370655</td>\n",
       "      <td>2.177762</td>\n",
       "      <td>2.399854</td>\n",
       "      <td>0.839253</td>\n",
       "      <td>2.297545</td>\n",
       "      <td>1.063690</td>\n",
       "      <td>0.586295</td>\n",
       "      <td>1.246520</td>\n",
       "      <td>1.062637</td>\n",
       "      <td>1.304793</td>\n",
       "      <td>1.685443</td>\n",
       "      <td>0.244599</td>\n",
       "      <td>1.340051</td>\n",
       "      <td>1.035505</td>\n",
       "      <td>1.499634</td>\n",
       "      <td>1.452346</td>\n",
       "      <td>1.627890</td>\n",
       "      <td>1.613636</td>\n",
       "      <td>1.158974</td>\n",
       "      <td>0.943652</td>\n",
       "      <td>27.896199</td>\n",
       "      <td>41.088923</td>\n",
       "      <td>57.763622</td>\n",
       "      <td>1.060588</td>\n",
       "      <td>0.580409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.574648</td>\n",
       "      <td>0.483591</td>\n",
       "      <td>22.341862</td>\n",
       "      <td>5.113934</td>\n",
       "      <td>7.473764</td>\n",
       "      <td>44.569040</td>\n",
       "      <td>5.567287</td>\n",
       "      <td>13.611226</td>\n",
       "      <td>13.665196</td>\n",
       "      <td>17.061225</td>\n",
       "      <td>2.014072</td>\n",
       "      <td>3.189662</td>\n",
       "      <td>17.707751</td>\n",
       "      <td>11.807781</td>\n",
       "      <td>0.499549</td>\n",
       "      <td>10.833995</td>\n",
       "      <td>0.612585</td>\n",
       "      <td>11.148951</td>\n",
       "      <td>0.612344</td>\n",
       "      <td>7.390161</td>\n",
       "      <td>0.470407</td>\n",
       "      <td>3.429301</td>\n",
       "      <td>0.485769</td>\n",
       "      <td>3.422167</td>\n",
       "      <td>0.485469</td>\n",
       "      <td>2.988863</td>\n",
       "      <td>0.410525</td>\n",
       "      <td>1.028267</td>\n",
       "      <td>92.586325</td>\n",
       "      <td>5.047848</td>\n",
       "      <td>1872.383246</td>\n",
       "      <td>2836.246272</td>\n",
       "      <td>73.266287</td>\n",
       "      <td>199.433753</td>\n",
       "      <td>5.792505</td>\n",
       "      <td>6.356402</td>\n",
       "      <td>199.372119</td>\n",
       "      <td>0.680635</td>\n",
       "      <td>56.272346</td>\n",
       "      <td>70.21561</td>\n",
       "      <td>108.705918</td>\n",
       "      <td>84.050607</td>\n",
       "      <td>129.362539</td>\n",
       "      <td>0.849476</td>\n",
       "      <td>0.783937</td>\n",
       "      <td>1.673312</td>\n",
       "      <td>1.697117</td>\n",
       "      <td>1.588807</td>\n",
       "      <td>1.195601</td>\n",
       "      <td>1.705218</td>\n",
       "      <td>1.268282</td>\n",
       "      <td>1.049355</td>\n",
       "      <td>1.342582</td>\n",
       "      <td>1.258797</td>\n",
       "      <td>1.331715</td>\n",
       "      <td>1.543074</td>\n",
       "      <td>0.522956</td>\n",
       "      <td>1.411156</td>\n",
       "      <td>1.301712</td>\n",
       "      <td>1.492929</td>\n",
       "      <td>1.495600</td>\n",
       "      <td>1.445622</td>\n",
       "      <td>1.529178</td>\n",
       "      <td>1.343661</td>\n",
       "      <td>1.185460</td>\n",
       "      <td>20.338853</td>\n",
       "      <td>10.427433</td>\n",
       "      <td>13.196091</td>\n",
       "      <td>1.094875</td>\n",
       "      <td>0.771122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.789610</td>\n",
       "      <td>0.048267</td>\n",
       "      <td>813.397000</td>\n",
       "      <td>1073.450000</td>\n",
       "      <td>1.789450</td>\n",
       "      <td>28.900400</td>\n",
       "      <td>7.864850</td>\n",
       "      <td>-194.163000</td>\n",
       "      <td>-8745.080000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.489000</td>\n",
       "      <td>4.63581</td>\n",
       "      <td>23.620100</td>\n",
       "      <td>4.655730</td>\n",
       "      <td>20.589200</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>15.869350</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>57.200000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.966905</td>\n",
       "      <td>15.913600</td>\n",
       "      <td>1004.710000</td>\n",
       "      <td>1605.785000</td>\n",
       "      <td>11.109550</td>\n",
       "      <td>49.278100</td>\n",
       "      <td>13.408000</td>\n",
       "      <td>2.306915</td>\n",
       "      <td>8.602395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.463500</td>\n",
       "      <td>12.98315</td>\n",
       "      <td>45.204100</td>\n",
       "      <td>21.141550</td>\n",
       "      <td>35.887000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>17.937682</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.050000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.922720</td>\n",
       "      <td>17.966500</td>\n",
       "      <td>1115.380000</td>\n",
       "      <td>1863.980000</td>\n",
       "      <td>15.928000</td>\n",
       "      <td>61.066200</td>\n",
       "      <td>14.092500</td>\n",
       "      <td>3.698630</td>\n",
       "      <td>16.174600</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.855800</td>\n",
       "      <td>16.43880</td>\n",
       "      <td>56.996400</td>\n",
       "      <td>27.415100</td>\n",
       "      <td>44.987000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>21.571244</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>113.800000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.175000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.460925</td>\n",
       "      <td>21.461100</td>\n",
       "      <td>1310.360000</td>\n",
       "      <td>2218.145000</td>\n",
       "      <td>25.162200</td>\n",
       "      <td>81.833800</td>\n",
       "      <td>15.430950</td>\n",
       "      <td>5.987690</td>\n",
       "      <td>30.273100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>35.475700</td>\n",
       "      <td>22.16760</td>\n",
       "      <td>77.105650</td>\n",
       "      <td>38.179400</td>\n",
       "      <td>60.271050</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>3.160000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>59.132048</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>123.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4115.360000</td>\n",
       "      <td>53.924300</td>\n",
       "      <td>83152.200000</td>\n",
       "      <td>124728.000000</td>\n",
       "      <td>3233.000000</td>\n",
       "      <td>8799.080000</td>\n",
       "      <td>217.771000</td>\n",
       "      <td>28.251500</td>\n",
       "      <td>153.820000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2457.910000</td>\n",
       "      <td>3108.17000</td>\n",
       "      <td>4683.710000</td>\n",
       "      <td>3607.690000</td>\n",
       "      <td>5690.910000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.790000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Basic_Demos-Age  Basic_Demos-Sex  CGAS-CGAS_Score  Physical-BMI  \\\n",
       "count      3960.000000      3960.000000      2421.000000   3022.000000   \n",
       "mean         10.433586         0.372727        65.454771     19.331929   \n",
       "std           3.574648         0.483591        22.341862      5.113934   \n",
       "min           5.000000         0.000000        25.000000      0.000000   \n",
       "25%           8.000000         0.000000        59.000000     15.869350   \n",
       "50%          10.000000         0.000000        65.000000     17.937682   \n",
       "75%          13.000000         1.000000        75.000000     21.571244   \n",
       "max          22.000000         1.000000       999.000000     59.132048   \n",
       "\n",
       "       Physical-Height  Physical-Weight  Physical-Waist_Circumference  \\\n",
       "count      3027.000000      3076.000000                    898.000000   \n",
       "mean         55.946713        89.038615                     27.278508   \n",
       "std           7.473764        44.569040                      5.567287   \n",
       "min          33.000000         0.000000                     18.000000   \n",
       "25%          50.000000        57.200000                     23.000000   \n",
       "50%          55.000000        77.000000                     26.000000   \n",
       "75%          62.000000       113.800000                     30.000000   \n",
       "max          78.500000       315.000000                     50.000000   \n",
       "\n",
       "       Physical-Diastolic_BP  Physical-HeartRate  Physical-Systolic_BP  \\\n",
       "count            2954.000000         2967.000000           2954.000000   \n",
       "mean               69.648951           81.597236            116.983074   \n",
       "std                13.611226           13.665196             17.061225   \n",
       "min                 0.000000           27.000000              0.000000   \n",
       "25%                61.000000           72.000000            107.000000   \n",
       "50%                68.000000           81.000000            114.000000   \n",
       "75%                76.000000           90.500000            125.000000   \n",
       "max               179.000000          138.000000            203.000000   \n",
       "\n",
       "       Fitness_Endurance-Max_Stage  Fitness_Endurance-Time_Mins  \\\n",
       "count                   743.000000                   740.000000   \n",
       "mean                      4.989233                     7.370270   \n",
       "std                       2.014072                     3.189662   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       4.000000                     6.000000   \n",
       "50%                       5.000000                     7.000000   \n",
       "75%                       6.000000                     9.000000   \n",
       "max                      28.000000                    20.000000   \n",
       "\n",
       "       Fitness_Endurance-Time_Sec   FGC-FGC_CU  FGC-FGC_CU_Zone  FGC-FGC_GSND  \\\n",
       "count                  740.000000  2322.000000      2282.000000   1074.000000   \n",
       "mean                    27.581081    11.259690         0.476337     22.420438   \n",
       "std                     17.707751    11.807781         0.499549     10.833995   \n",
       "min                      0.000000     0.000000         0.000000      0.000000   \n",
       "25%                     12.750000     3.000000         0.000000     15.100000   \n",
       "50%                     28.000000     9.000000         0.000000     20.050000   \n",
       "75%                     43.000000    15.750000         1.000000     26.600000   \n",
       "max                     59.000000   115.000000         1.000000    124.000000   \n",
       "\n",
       "       FGC-FGC_GSND_Zone  FGC-FGC_GSD  FGC-FGC_GSD_Zone   FGC-FGC_PU  \\\n",
       "count        1062.000000  1074.000000       1063.000000  2310.000000   \n",
       "mean            1.829567    23.518622          1.904045     5.579654   \n",
       "std             0.612585    11.148951          0.612344     7.390161   \n",
       "min             1.000000     0.000000          1.000000     0.000000   \n",
       "25%             1.000000    16.200000          2.000000     0.000000   \n",
       "50%             2.000000    21.200000          2.000000     3.000000   \n",
       "75%             2.000000    28.175000          2.000000     9.000000   \n",
       "max             3.000000   123.800000          3.000000    51.000000   \n",
       "\n",
       "       FGC-FGC_PU_Zone  FGC-FGC_SRL  FGC-FGC_SRL_Zone  FGC-FGC_SRR  \\\n",
       "count      2271.000000  2305.000000       2267.000000  2307.000000   \n",
       "mean          0.330251     8.694924          0.618880     8.805635   \n",
       "std           0.470407     3.429301          0.485769     3.422167   \n",
       "min           0.000000     0.000000          0.000000     0.000000   \n",
       "25%           0.000000     7.000000          0.000000     7.000000   \n",
       "50%           0.000000     9.000000          1.000000     9.000000   \n",
       "75%           1.000000    11.000000          1.000000    11.000000   \n",
       "max           1.000000    21.700000          1.000000    21.000000   \n",
       "\n",
       "       FGC-FGC_SRR_Zone   FGC-FGC_TL  FGC-FGC_TL_Zone  \\\n",
       "count       2269.000000  2324.000000      2285.000000   \n",
       "mean           0.620097     9.252775         0.785558   \n",
       "std            0.485469     2.988863         0.410525   \n",
       "min            0.000000     0.000000         0.000000   \n",
       "25%            0.000000     7.000000         1.000000   \n",
       "50%            1.000000    10.000000         1.000000   \n",
       "75%            1.000000    12.000000         1.000000   \n",
       "max            1.000000    22.000000         1.000000   \n",
       "\n",
       "       BIA-BIA_Activity_Level_num  BIA-BIA_BMC  BIA-BIA_BMI   BIA-BIA_BMR  \\\n",
       "count                 1991.000000  1991.000000  1991.000000   1991.000000   \n",
       "mean                     2.651431     6.719826    19.367048   1237.018187   \n",
       "std                      1.028267    92.586325     5.047848   1872.383246   \n",
       "min                      1.000000    -7.789610     0.048267    813.397000   \n",
       "25%                      2.000000     2.966905    15.913600   1004.710000   \n",
       "50%                      3.000000     3.922720    17.966500   1115.380000   \n",
       "75%                      3.000000     5.460925    21.461100   1310.360000   \n",
       "max                      5.000000  4115.360000    53.924300  83152.200000   \n",
       "\n",
       "         BIA-BIA_DEE  BIA-BIA_ECW  BIA-BIA_FFM  BIA-BIA_FFMI  BIA-BIA_FMI  \\\n",
       "count    1991.000000  1991.000000  1991.000000   1991.000000  1991.000000   \n",
       "mean     2064.693747    20.825346    74.021708     15.030554     4.336495   \n",
       "std      2836.246272    73.266287   199.433753      5.792505     6.356402   \n",
       "min      1073.450000     1.789450    28.900400      7.864850  -194.163000   \n",
       "25%      1605.785000    11.109550    49.278100     13.408000     2.306915   \n",
       "50%      1863.980000    15.928000    61.066200     14.092500     3.698630   \n",
       "75%      2218.145000    25.162200    81.833800     15.430950     5.987690   \n",
       "max    124728.000000  3233.000000  8799.080000    217.771000    28.251500   \n",
       "\n",
       "       BIA-BIA_Fat  BIA-BIA_Frame_num  BIA-BIA_ICW  BIA-BIA_LDM  BIA-BIA_LST  \\\n",
       "count  1991.000000        1991.000000  1991.000000   1991.00000  1991.000000   \n",
       "mean     16.855020           1.745354    33.173380     20.02299    67.301883   \n",
       "std     199.372119           0.680635    56.272346     70.21561   108.705918   \n",
       "min   -8745.080000           1.000000    14.489000      4.63581    23.620100   \n",
       "25%       8.602395           1.000000    24.463500     12.98315    45.204100   \n",
       "50%      16.174600           2.000000    28.855800     16.43880    56.996400   \n",
       "75%      30.273100           2.000000    35.475700     22.16760    77.105650   \n",
       "max     153.820000           3.000000  2457.910000   3108.17000  4683.710000   \n",
       "\n",
       "       BIA-BIA_SMM  BIA-BIA_TBW  PAQ_A-PAQ_A_Total  PAQ_C-PAQ_C_Total  \\\n",
       "count  1991.000000  1991.000000         475.000000        1721.000000   \n",
       "mean     34.389466    53.998726           2.178853           2.589550   \n",
       "std      84.050607   129.362539           0.849476           0.783937   \n",
       "min       4.655730    20.589200           0.660000           0.580000   \n",
       "25%      21.141550    35.887000           1.490000           2.020000   \n",
       "50%      27.415100    44.987000           2.010000           2.540000   \n",
       "75%      38.179400    60.271050           2.780000           3.160000   \n",
       "max    3607.690000  5690.910000           4.710000           4.790000   \n",
       "\n",
       "       PCIAT-PCIAT_01  PCIAT-PCIAT_02  PCIAT-PCIAT_03  PCIAT-PCIAT_04  \\\n",
       "count     2733.000000     2734.000000     2731.000000     2731.000000   \n",
       "mean         2.370655        2.177762        2.399854        0.839253   \n",
       "std          1.673312        1.697117        1.588807        1.195601   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          1.000000        1.000000        1.000000        0.000000   \n",
       "50%          2.000000        2.000000        2.000000        0.000000   \n",
       "75%          4.000000        4.000000        4.000000        1.000000   \n",
       "max          5.000000        5.000000        5.000000        5.000000   \n",
       "\n",
       "       PCIAT-PCIAT_05  PCIAT-PCIAT_06  PCIAT-PCIAT_07  PCIAT-PCIAT_08  \\\n",
       "count     2729.000000     2732.000000     2729.000000     2730.000000   \n",
       "mean         2.297545        1.063690        0.586295        1.246520   \n",
       "std          1.705218        1.268282        1.049355        1.342582   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          1.000000        0.000000        0.000000        0.000000   \n",
       "50%          2.000000        1.000000        0.000000        1.000000   \n",
       "75%          4.000000        2.000000        1.000000        2.000000   \n",
       "max          5.000000        5.000000        5.000000        5.000000   \n",
       "\n",
       "       PCIAT-PCIAT_09  PCIAT-PCIAT_10  PCIAT-PCIAT_11  PCIAT-PCIAT_12  \\\n",
       "count     2730.000000     2733.000000     2734.000000     2731.000000   \n",
       "mean         1.062637        1.304793        1.685443        0.244599   \n",
       "std          1.258797        1.331715        1.543074        0.522956   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          1.000000        1.000000        2.000000        0.000000   \n",
       "75%          2.000000        2.000000        3.000000        0.000000   \n",
       "max          5.000000        5.000000        5.000000        5.000000   \n",
       "\n",
       "       PCIAT-PCIAT_13  PCIAT-PCIAT_14  PCIAT-PCIAT_15  PCIAT-PCIAT_16  \\\n",
       "count     2729.000000     2732.000000     2730.000000     2728.000000   \n",
       "mean         1.340051        1.035505        1.499634        1.452346   \n",
       "std          1.411156        1.301712        1.492929        1.495600   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          1.000000        1.000000        1.000000        1.000000   \n",
       "75%          2.000000        2.000000        2.000000        2.000000   \n",
       "max          5.000000        5.000000        5.000000        5.000000   \n",
       "\n",
       "       PCIAT-PCIAT_17  PCIAT-PCIAT_18  PCIAT-PCIAT_19  PCIAT-PCIAT_20  \\\n",
       "count     2725.000000     2728.000000     2730.000000     2733.000000   \n",
       "mean         1.627890        1.613636        1.158974        0.943652   \n",
       "std          1.445622        1.529178        1.343661        1.185460   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          1.000000        1.000000        1.000000        1.000000   \n",
       "75%          3.000000        2.000000        2.000000        1.000000   \n",
       "max          5.000000        5.000000        5.000000        5.000000   \n",
       "\n",
       "       PCIAT-PCIAT_Total  SDS-SDS_Total_Raw  SDS-SDS_Total_T  \\\n",
       "count        2736.000000        2609.000000      2606.000000   \n",
       "mean           27.896199          41.088923        57.763622   \n",
       "std            20.338853          10.427433        13.196091   \n",
       "min             0.000000          17.000000        38.000000   \n",
       "25%            12.000000          33.000000        47.000000   \n",
       "50%            26.000000          39.000000        55.000000   \n",
       "75%            41.000000          46.000000        64.000000   \n",
       "max            93.000000          96.000000       100.000000   \n",
       "\n",
       "       PreInt_EduHx-computerinternet_hoursday          sii  \n",
       "count                             3301.000000  2736.000000  \n",
       "mean                                 1.060588     0.580409  \n",
       "std                                  1.094875     0.771122  \n",
       "min                                  0.000000     0.000000  \n",
       "25%                                  0.000000     0.000000  \n",
       "50%                                  1.000000     0.000000  \n",
       "75%                                  2.000000     1.000000  \n",
       "max                                  3.000000     3.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    00008ff9\n",
       "1    000fd460\n",
       "2    00105258\n",
       "3    00115b9f\n",
       "4    0016bb22\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load timeseries data\n",
    "- process_file: This function process file timeseries, extract general information in the file like count, mean, std, min, 25%, 50%, 75% and max of each features and then the features matrix is flattened to a vector to represent the data in the file\n",
    "- load_time_series Format and load all timeseries files after processed in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"Stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim * 4),\n",
    "            nn.BatchNorm1d(encoding_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(encoding_dim * 4, encoding_dim * 3),\n",
    "            nn.BatchNorm1d(encoding_dim * 3),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "\n",
    "            nn.Linear(encoding_dim * 3, encoding_dim * 2),\n",
    "            nn.BatchNorm1d(encoding_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(encoding_dim * 2, encoding_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, encoding_dim * 2),\n",
    "            nn.BatchNorm1d(encoding_dim * 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(encoding_dim * 2, encoding_dim * 3),\n",
    "            nn.BatchNorm1d(encoding_dim * 3),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(encoding_dim * 3, encoding_dim * 4),\n",
    "            nn.BatchNorm1d(encoding_dim * 4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(encoding_dim * 4, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    data_tensor = torch.FloatTensor(df_scaled)\n",
    "    \n",
    "    input_dim = data_tensor.shape[1]\n",
    "    autoencoder = AutoEncoder(input_dim, encoding_dim)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(data_tensor), batch_size):\n",
    "            batch = data_tensor[i : i + batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = autoencoder(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]')\n",
    "                 \n",
    "    with torch.no_grad():\n",
    "        encoded_data = autoencoder.encoder(data_tensor).numpy()\n",
    "        \n",
    "    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "class TabNetWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = TabNetRegressor(**kwargs)\n",
    "        self.kwargs = kwargs\n",
    "        self.imputer = SimpleImputer(strategy='median')\n",
    "        self.best_model_path = 'best_tabnet_model.pt'\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Handle missing values\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "        \n",
    "        if hasattr(y, 'values'):\n",
    "            y = y.values\n",
    "            \n",
    "        # Create internal validation set\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_imputed, \n",
    "            y, \n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train TabNet model\n",
    "        history = self.model.fit(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train.reshape(-1, 1),\n",
    "            eval_set=[(X_valid, y_valid.reshape(-1, 1))],\n",
    "            eval_name=['valid'],\n",
    "            eval_metric=['mse'],\n",
    "            max_epochs=200,\n",
    "            patience=20,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            callbacks=[\n",
    "                TabNetPretrainedModelCheckpoint(\n",
    "                    filepath=self.best_model_path,\n",
    "                    monitor='valid_mse',\n",
    "                    mode='min',\n",
    "                    save_best_only=True,\n",
    "                    verbose=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Load the best model\n",
    "        if os.path.exists(self.best_model_path):\n",
    "            self.model.load_model(self.best_model_path)\n",
    "            os.remove(self.best_model_path)  # Remove temporary file\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "        return self.model.predict(X_imputed).flatten()\n",
    "    \n",
    "    def __deepcopy__(self, memo):\n",
    "        # Add deepcopy support for scikit-learn\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            setattr(result, k, deepcopy(v, memo))\n",
    "        return result\n",
    "\n",
    "class TabNetPretrainedModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, monitor='val_loss', mode='min', \n",
    "                 save_best_only=True, verbose=1):\n",
    "        super().__init__()  # Initialize parent class\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_best_only = save_best_only\n",
    "        self.verbose = verbose\n",
    "        self.best = float('inf') if mode == 'min' else -float('inf')\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.model = self.trainer  # Use trainer itself as model\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "        \n",
    "        # Check if current metric is better than best\n",
    "        if (self.mode == 'min' and current < self.best) or \\\n",
    "           (self.mode == 'max' and current > self.best):\n",
    "            if self.verbose:\n",
    "                print(f'\\nEpoch {epoch}: {self.monitor} improved from {self.best:.4f} to {current:.4f}')\n",
    "            self.best = current\n",
    "            if self.save_best_only:\n",
    "                self.model.save_model(self.filepath)  # Save the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 995/995 [02:02<00:00,  8.15it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6250]\n",
      "Epoch [20/100], Loss: 0.5755]\n",
      "Epoch [30/100], Loss: 0.5611]\n",
      "Epoch [40/100], Loss: 0.5565]\n",
      "Epoch [50/100], Loss: 0.5559]\n",
      "Epoch [60/100], Loss: 0.5549]\n",
      "Epoch [70/100], Loss: 0.5531]\n",
      "Epoch [80/100], Loss: 0.5534]\n",
      "Epoch [90/100], Loss: 0.5513]\n",
      "Epoch [100/100], Loss: 0.5529]\n",
      "Epoch [10/100], Loss: 0.9181]\n",
      "Epoch [20/100], Loss: 0.7982]\n",
      "Epoch [30/100], Loss: 0.6482]\n",
      "Epoch [40/100], Loss: 0.5986]\n",
      "Epoch [50/100], Loss: 0.4971]\n",
      "Epoch [60/100], Loss: 0.4700]\n",
      "Epoch [70/100], Loss: 0.4597]\n",
      "Epoch [80/100], Loss: 0.4486]\n",
      "Epoch [90/100], Loss: 0.4417]\n",
      "Epoch [100/100], Loss: 0.4392]\n"
     ]
    }
   ],
   "source": [
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "df_train = train_ts.drop('id', axis=1)\n",
    "df_test = test_ts.drop('id', axis=1)\n",
    "train_ts_encoded = perform_autoencoder(df_train, encoding_dim=60, epochs=100, batch_size=32)\n",
    "test_ts_encoded = perform_autoencoder(df_test, encoding_dim=60, epochs=100, batch_size=32)\n",
    "\n",
    "time_series_cols = train_ts_encoded.columns.tolist()\n",
    "train_ts_encoded[\"id\"]=train_ts[\"id\"]\n",
    "test_ts_encoded['id']=test_ts[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_ts_encoded, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts_encoded, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>Physical-Diastolic_BP</th>\n",
       "      <th>Physical-HeartRate</th>\n",
       "      <th>Physical-Systolic_BP</th>\n",
       "      <th>Fitness_Endurance-Season</th>\n",
       "      <th>Fitness_Endurance-Max_Stage</th>\n",
       "      <th>Fitness_Endurance-Time_Mins</th>\n",
       "      <th>Fitness_Endurance-Time_Sec</th>\n",
       "      <th>FGC-Season</th>\n",
       "      <th>FGC-FGC_CU</th>\n",
       "      <th>FGC-FGC_CU_Zone</th>\n",
       "      <th>FGC-FGC_GSND</th>\n",
       "      <th>FGC-FGC_GSND_Zone</th>\n",
       "      <th>FGC-FGC_GSD</th>\n",
       "      <th>FGC-FGC_GSD_Zone</th>\n",
       "      <th>FGC-FGC_PU</th>\n",
       "      <th>FGC-FGC_PU_Zone</th>\n",
       "      <th>FGC-FGC_SRL</th>\n",
       "      <th>FGC-FGC_SRL_Zone</th>\n",
       "      <th>FGC-FGC_SRR</th>\n",
       "      <th>FGC-FGC_SRR_Zone</th>\n",
       "      <th>FGC-FGC_TL</th>\n",
       "      <th>FGC-FGC_TL_Zone</th>\n",
       "      <th>BIA-Season</th>\n",
       "      <th>BIA-BIA_Activity_Level_num</th>\n",
       "      <th>BIA-BIA_BMC</th>\n",
       "      <th>BIA-BIA_BMI</th>\n",
       "      <th>BIA-BIA_BMR</th>\n",
       "      <th>BIA-BIA_DEE</th>\n",
       "      <th>BIA-BIA_ECW</th>\n",
       "      <th>BIA-BIA_FFM</th>\n",
       "      <th>BIA-BIA_FFMI</th>\n",
       "      <th>BIA-BIA_FMI</th>\n",
       "      <th>BIA-BIA_Fat</th>\n",
       "      <th>BIA-BIA_Frame_num</th>\n",
       "      <th>BIA-BIA_ICW</th>\n",
       "      <th>BIA-BIA_LDM</th>\n",
       "      <th>BIA-BIA_LST</th>\n",
       "      <th>BIA-BIA_SMM</th>\n",
       "      <th>BIA-BIA_TBW</th>\n",
       "      <th>PAQ_A-Season</th>\n",
       "      <th>PAQ_A-PAQ_A_Total</th>\n",
       "      <th>PAQ_C-Season</th>\n",
       "      <th>PAQ_C-PAQ_C_Total</th>\n",
       "      <th>PCIAT-Season</th>\n",
       "      <th>PCIAT-PCIAT_01</th>\n",
       "      <th>PCIAT-PCIAT_02</th>\n",
       "      <th>PCIAT-PCIAT_03</th>\n",
       "      <th>PCIAT-PCIAT_04</th>\n",
       "      <th>PCIAT-PCIAT_05</th>\n",
       "      <th>PCIAT-PCIAT_06</th>\n",
       "      <th>PCIAT-PCIAT_07</th>\n",
       "      <th>PCIAT-PCIAT_08</th>\n",
       "      <th>PCIAT-PCIAT_09</th>\n",
       "      <th>PCIAT-PCIAT_10</th>\n",
       "      <th>PCIAT-PCIAT_11</th>\n",
       "      <th>PCIAT-PCIAT_12</th>\n",
       "      <th>PCIAT-PCIAT_13</th>\n",
       "      <th>PCIAT-PCIAT_14</th>\n",
       "      <th>PCIAT-PCIAT_15</th>\n",
       "      <th>PCIAT-PCIAT_16</th>\n",
       "      <th>PCIAT-PCIAT_17</th>\n",
       "      <th>PCIAT-PCIAT_18</th>\n",
       "      <th>PCIAT-PCIAT_19</th>\n",
       "      <th>PCIAT-PCIAT_20</th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "      <th>Enc_1</th>\n",
       "      <th>Enc_2</th>\n",
       "      <th>Enc_3</th>\n",
       "      <th>Enc_4</th>\n",
       "      <th>Enc_5</th>\n",
       "      <th>Enc_6</th>\n",
       "      <th>Enc_7</th>\n",
       "      <th>Enc_8</th>\n",
       "      <th>Enc_9</th>\n",
       "      <th>Enc_10</th>\n",
       "      <th>Enc_11</th>\n",
       "      <th>Enc_12</th>\n",
       "      <th>Enc_13</th>\n",
       "      <th>Enc_14</th>\n",
       "      <th>Enc_15</th>\n",
       "      <th>Enc_16</th>\n",
       "      <th>Enc_17</th>\n",
       "      <th>Enc_18</th>\n",
       "      <th>Enc_19</th>\n",
       "      <th>Enc_20</th>\n",
       "      <th>Enc_21</th>\n",
       "      <th>Enc_22</th>\n",
       "      <th>Enc_23</th>\n",
       "      <th>Enc_24</th>\n",
       "      <th>Enc_25</th>\n",
       "      <th>Enc_26</th>\n",
       "      <th>Enc_27</th>\n",
       "      <th>Enc_28</th>\n",
       "      <th>Enc_29</th>\n",
       "      <th>Enc_30</th>\n",
       "      <th>Enc_31</th>\n",
       "      <th>Enc_32</th>\n",
       "      <th>Enc_33</th>\n",
       "      <th>Enc_34</th>\n",
       "      <th>Enc_35</th>\n",
       "      <th>Enc_36</th>\n",
       "      <th>Enc_37</th>\n",
       "      <th>Enc_38</th>\n",
       "      <th>Enc_39</th>\n",
       "      <th>Enc_40</th>\n",
       "      <th>Enc_41</th>\n",
       "      <th>Enc_42</th>\n",
       "      <th>Enc_43</th>\n",
       "      <th>Enc_44</th>\n",
       "      <th>Enc_45</th>\n",
       "      <th>Enc_46</th>\n",
       "      <th>Enc_47</th>\n",
       "      <th>Enc_48</th>\n",
       "      <th>Enc_49</th>\n",
       "      <th>Enc_50</th>\n",
       "      <th>Enc_51</th>\n",
       "      <th>Enc_52</th>\n",
       "      <th>Enc_53</th>\n",
       "      <th>Enc_54</th>\n",
       "      <th>Enc_55</th>\n",
       "      <th>Enc_56</th>\n",
       "      <th>Enc_57</th>\n",
       "      <th>Enc_58</th>\n",
       "      <th>Enc_59</th>\n",
       "      <th>Enc_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.66855</td>\n",
       "      <td>16.8792</td>\n",
       "      <td>932.498</td>\n",
       "      <td>1492.00</td>\n",
       "      <td>8.25598</td>\n",
       "      <td>41.5862</td>\n",
       "      <td>13.8177</td>\n",
       "      <td>3.06143</td>\n",
       "      <td>9.21377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.4349</td>\n",
       "      <td>8.89536</td>\n",
       "      <td>38.9177</td>\n",
       "      <td>19.5413</td>\n",
       "      <td>32.6909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.57949</td>\n",
       "      <td>14.0371</td>\n",
       "      <td>936.656</td>\n",
       "      <td>1498.65</td>\n",
       "      <td>6.01993</td>\n",
       "      <td>42.0291</td>\n",
       "      <td>12.8254</td>\n",
       "      <td>1.21172</td>\n",
       "      <td>3.97085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0352</td>\n",
       "      <td>14.97400</td>\n",
       "      <td>39.4497</td>\n",
       "      <td>15.4107</td>\n",
       "      <td>27.0552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2.340</td>\n",
       "      <td>Fall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.170</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.84191</td>\n",
       "      <td>18.2943</td>\n",
       "      <td>1131.430</td>\n",
       "      <td>1923.44</td>\n",
       "      <td>15.59250</td>\n",
       "      <td>62.7757</td>\n",
       "      <td>14.0740</td>\n",
       "      <td>4.22033</td>\n",
       "      <td>18.82430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.4041</td>\n",
       "      <td>16.77900</td>\n",
       "      <td>58.9338</td>\n",
       "      <td>26.4798</td>\n",
       "      <td>45.9966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.451</td>\n",
       "      <td>Summer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105177</td>\n",
       "      <td>-0.211024</td>\n",
       "      <td>-0.399976</td>\n",
       "      <td>-0.41677</td>\n",
       "      <td>-0.851182</td>\n",
       "      <td>0.944888</td>\n",
       "      <td>-0.011823</td>\n",
       "      <td>0.465943</td>\n",
       "      <td>-0.731888</td>\n",
       "      <td>-0.703341</td>\n",
       "      <td>0.276331</td>\n",
       "      <td>-0.448848</td>\n",
       "      <td>0.687481</td>\n",
       "      <td>-0.207199</td>\n",
       "      <td>0.244792</td>\n",
       "      <td>0.091883</td>\n",
       "      <td>0.492591</td>\n",
       "      <td>0.41136</td>\n",
       "      <td>-0.104185</td>\n",
       "      <td>-0.406217</td>\n",
       "      <td>0.506578</td>\n",
       "      <td>0.434309</td>\n",
       "      <td>0.171246</td>\n",
       "      <td>-0.298024</td>\n",
       "      <td>-0.151346</td>\n",
       "      <td>0.156348</td>\n",
       "      <td>0.749452</td>\n",
       "      <td>-0.349632</td>\n",
       "      <td>-0.789029</td>\n",
       "      <td>0.137722</td>\n",
       "      <td>0.72069</td>\n",
       "      <td>-0.254042</td>\n",
       "      <td>-0.104482</td>\n",
       "      <td>-0.408103</td>\n",
       "      <td>0.308529</td>\n",
       "      <td>0.705924</td>\n",
       "      <td>0.55378</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>-0.763368</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>-0.5606</td>\n",
       "      <td>-0.123938</td>\n",
       "      <td>-0.224512</td>\n",
       "      <td>-0.267055</td>\n",
       "      <td>-0.522073</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>0.147435</td>\n",
       "      <td>0.153031</td>\n",
       "      <td>0.30701</td>\n",
       "      <td>0.040291</td>\n",
       "      <td>0.069071</td>\n",
       "      <td>-0.612262</td>\n",
       "      <td>-0.846278</td>\n",
       "      <td>-0.079514</td>\n",
       "      <td>-0.594889</td>\n",
       "      <td>0.480708</td>\n",
       "      <td>-0.034761</td>\n",
       "      <td>-0.165725</td>\n",
       "      <td>0.417818</td>\n",
       "      <td>-0.311721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex CGAS-Season  \\\n",
       "0                      Fall                5                0      Winter   \n",
       "1                    Summer                9                0         NaN   \n",
       "2                    Summer               10                1        Fall   \n",
       "3                    Winter                9                0        Fall   \n",
       "4                    Spring               18                1      Summer   \n",
       "\n",
       "   CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n",
       "0             51.0            Fall     16.877316             46.0   \n",
       "1              NaN            Fall     14.035590             48.0   \n",
       "2             71.0            Fall     16.648696             56.5   \n",
       "3             71.0          Summer     18.292347             56.0   \n",
       "4              NaN             NaN           NaN              NaN   \n",
       "\n",
       "   Physical-Weight  Physical-Waist_Circumference  Physical-Diastolic_BP  \\\n",
       "0             50.8                           NaN                    NaN   \n",
       "1             46.0                          22.0                   75.0   \n",
       "2             75.6                           NaN                   65.0   \n",
       "3             81.6                           NaN                   60.0   \n",
       "4              NaN                           NaN                    NaN   \n",
       "\n",
       "   Physical-HeartRate  Physical-Systolic_BP Fitness_Endurance-Season  \\\n",
       "0                 NaN                   NaN                      NaN   \n",
       "1                70.0                 122.0                      NaN   \n",
       "2                94.0                 117.0                     Fall   \n",
       "3                97.0                 117.0                   Summer   \n",
       "4                 NaN                   NaN                      NaN   \n",
       "\n",
       "   Fitness_Endurance-Max_Stage  Fitness_Endurance-Time_Mins  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          5.0                          7.0   \n",
       "3                          6.0                          9.0   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   Fitness_Endurance-Time_Sec FGC-Season  FGC-FGC_CU  FGC-FGC_CU_Zone  \\\n",
       "0                         NaN       Fall         0.0              0.0   \n",
       "1                         NaN       Fall         3.0              0.0   \n",
       "2                        33.0       Fall        20.0              1.0   \n",
       "3                        37.0     Summer        18.0              1.0   \n",
       "4                         NaN        NaN         NaN              NaN   \n",
       "\n",
       "   FGC-FGC_GSND  FGC-FGC_GSND_Zone  FGC-FGC_GSD  FGC-FGC_GSD_Zone  FGC-FGC_PU  \\\n",
       "0           NaN                NaN          NaN               NaN         0.0   \n",
       "1           NaN                NaN          NaN               NaN         5.0   \n",
       "2          10.2                1.0         14.7               2.0         7.0   \n",
       "3           NaN                NaN          NaN               NaN         5.0   \n",
       "4           NaN                NaN          NaN               NaN         NaN   \n",
       "\n",
       "   FGC-FGC_PU_Zone  FGC-FGC_SRL  FGC-FGC_SRL_Zone  FGC-FGC_SRR  \\\n",
       "0              0.0          7.0               0.0          6.0   \n",
       "1              0.0         11.0               1.0         11.0   \n",
       "2              1.0         10.0               1.0         10.0   \n",
       "3              0.0          7.0               0.0          7.0   \n",
       "4              NaN          NaN               NaN          NaN   \n",
       "\n",
       "   FGC-FGC_SRR_Zone  FGC-FGC_TL  FGC-FGC_TL_Zone BIA-Season  \\\n",
       "0               0.0         6.0              1.0       Fall   \n",
       "1               1.0         3.0              0.0     Winter   \n",
       "2               1.0         5.0              0.0        NaN   \n",
       "3               0.0         7.0              1.0     Summer   \n",
       "4               NaN         NaN              NaN        NaN   \n",
       "\n",
       "   BIA-BIA_Activity_Level_num  BIA-BIA_BMC  BIA-BIA_BMI  BIA-BIA_BMR  \\\n",
       "0                         2.0      2.66855      16.8792      932.498   \n",
       "1                         2.0      2.57949      14.0371      936.656   \n",
       "2                         NaN          NaN          NaN          NaN   \n",
       "3                         3.0      3.84191      18.2943     1131.430   \n",
       "4                         NaN          NaN          NaN          NaN   \n",
       "\n",
       "   BIA-BIA_DEE  BIA-BIA_ECW  BIA-BIA_FFM  BIA-BIA_FFMI  BIA-BIA_FMI  \\\n",
       "0      1492.00      8.25598      41.5862       13.8177      3.06143   \n",
       "1      1498.65      6.01993      42.0291       12.8254      1.21172   \n",
       "2          NaN          NaN          NaN           NaN          NaN   \n",
       "3      1923.44     15.59250      62.7757       14.0740      4.22033   \n",
       "4          NaN          NaN          NaN           NaN          NaN   \n",
       "\n",
       "   BIA-BIA_Fat  BIA-BIA_Frame_num  BIA-BIA_ICW  BIA-BIA_LDM  BIA-BIA_LST  \\\n",
       "0      9.21377                1.0      24.4349      8.89536      38.9177   \n",
       "1      3.97085                1.0      21.0352     14.97400      39.4497   \n",
       "2          NaN                NaN          NaN          NaN          NaN   \n",
       "3     18.82430                2.0      30.4041     16.77900      58.9338   \n",
       "4          NaN                NaN          NaN          NaN          NaN   \n",
       "\n",
       "   BIA-BIA_SMM  BIA-BIA_TBW PAQ_A-Season  PAQ_A-PAQ_A_Total PAQ_C-Season  \\\n",
       "0      19.5413      32.6909          NaN                NaN          NaN   \n",
       "1      15.4107      27.0552          NaN                NaN         Fall   \n",
       "2          NaN          NaN          NaN                NaN       Summer   \n",
       "3      26.4798      45.9966          NaN                NaN       Winter   \n",
       "4          NaN          NaN       Summer               1.04          NaN   \n",
       "\n",
       "   PAQ_C-PAQ_C_Total PCIAT-Season  PCIAT-PCIAT_01  PCIAT-PCIAT_02  \\\n",
       "0                NaN         Fall             5.0             4.0   \n",
       "1              2.340         Fall             0.0             0.0   \n",
       "2              2.170         Fall             5.0             2.0   \n",
       "3              2.451       Summer             4.0             2.0   \n",
       "4                NaN          NaN             NaN             NaN   \n",
       "\n",
       "   PCIAT-PCIAT_03  PCIAT-PCIAT_04  PCIAT-PCIAT_05  PCIAT-PCIAT_06  \\\n",
       "0             4.0             0.0             4.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             2.0             1.0             2.0             1.0   \n",
       "3             4.0             0.0             5.0             1.0   \n",
       "4             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   PCIAT-PCIAT_07  PCIAT-PCIAT_08  PCIAT-PCIAT_09  PCIAT-PCIAT_10  \\\n",
       "0             0.0             4.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             1.0             2.0             1.0             1.0   \n",
       "3             0.0             3.0             2.0             2.0   \n",
       "4             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   PCIAT-PCIAT_11  PCIAT-PCIAT_12  PCIAT-PCIAT_13  PCIAT-PCIAT_14  \\\n",
       "0             4.0             0.0             4.0             4.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             1.0             0.0             1.0             1.0   \n",
       "3             3.0             0.0             3.0             0.0   \n",
       "4             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   PCIAT-PCIAT_15  PCIAT-PCIAT_16  PCIAT-PCIAT_17  PCIAT-PCIAT_18  \\\n",
       "0             4.0             4.0             4.0             4.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             1.0             0.0             2.0             2.0   \n",
       "3             0.0             3.0             4.0             3.0   \n",
       "4             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   PCIAT-PCIAT_19  PCIAT-PCIAT_20  PCIAT-PCIAT_Total SDS-Season  \\\n",
       "0             2.0             4.0               55.0        NaN   \n",
       "1             0.0             0.0                0.0       Fall   \n",
       "2             1.0             1.0               28.0       Fall   \n",
       "3             4.0             1.0               44.0     Summer   \n",
       "4             NaN             NaN                NaN        NaN   \n",
       "\n",
       "   SDS-SDS_Total_Raw  SDS-SDS_Total_T PreInt_EduHx-Season  \\\n",
       "0                NaN              NaN                Fall   \n",
       "1               46.0             64.0              Summer   \n",
       "2               38.0             54.0              Summer   \n",
       "3               31.0             45.0              Winter   \n",
       "4                NaN              NaN                 NaN   \n",
       "\n",
       "   PreInt_EduHx-computerinternet_hoursday  sii     Enc_1     Enc_2     Enc_3  \\\n",
       "0                                     3.0  2.0       NaN       NaN       NaN   \n",
       "1                                     0.0  0.0       NaN       NaN       NaN   \n",
       "2                                     2.0  0.0       NaN       NaN       NaN   \n",
       "3                                     0.0  1.0  0.105177 -0.211024 -0.399976   \n",
       "4                                     NaN  NaN       NaN       NaN       NaN   \n",
       "\n",
       "     Enc_4     Enc_5     Enc_6     Enc_7     Enc_8     Enc_9    Enc_10  \\\n",
       "0      NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1      NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2      NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3 -0.41677 -0.851182  0.944888 -0.011823  0.465943 -0.731888 -0.703341   \n",
       "4      NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "     Enc_11    Enc_12    Enc_13    Enc_14    Enc_15    Enc_16    Enc_17  \\\n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3  0.276331 -0.448848  0.687481 -0.207199  0.244792  0.091883  0.492591   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "    Enc_18    Enc_19    Enc_20    Enc_21    Enc_22    Enc_23    Enc_24  \\\n",
       "0      NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1      NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2      NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3  0.41136 -0.104185 -0.406217  0.506578  0.434309  0.171246 -0.298024   \n",
       "4      NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "     Enc_25    Enc_26    Enc_27    Enc_28    Enc_29    Enc_30   Enc_31  \\\n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "3 -0.151346  0.156348  0.749452 -0.349632 -0.789029  0.137722  0.72069   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "\n",
       "     Enc_32    Enc_33    Enc_34    Enc_35    Enc_36   Enc_37  Enc_38  \\\n",
       "0       NaN       NaN       NaN       NaN       NaN      NaN     NaN   \n",
       "1       NaN       NaN       NaN       NaN       NaN      NaN     NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN      NaN     NaN   \n",
       "3 -0.254042 -0.104482 -0.408103  0.308529  0.705924  0.55378  0.2515   \n",
       "4       NaN       NaN       NaN       NaN       NaN      NaN     NaN   \n",
       "\n",
       "     Enc_39    Enc_40  Enc_41    Enc_42    Enc_43    Enc_44    Enc_45  \\\n",
       "0       NaN       NaN     NaN       NaN       NaN       NaN       NaN   \n",
       "1       NaN       NaN     NaN       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN     NaN       NaN       NaN       NaN       NaN   \n",
       "3 -0.763368  0.021745 -0.5606 -0.123938 -0.224512 -0.267055 -0.522073   \n",
       "4       NaN       NaN     NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "     Enc_46    Enc_47    Enc_48   Enc_49    Enc_50    Enc_51    Enc_52  \\\n",
       "0       NaN       NaN       NaN      NaN       NaN       NaN       NaN   \n",
       "1       NaN       NaN       NaN      NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN      NaN       NaN       NaN       NaN   \n",
       "3  0.065973  0.147435  0.153031  0.30701  0.040291  0.069071 -0.612262   \n",
       "4       NaN       NaN       NaN      NaN       NaN       NaN       NaN   \n",
       "\n",
       "     Enc_53    Enc_54    Enc_55    Enc_56    Enc_57    Enc_58    Enc_59  \\\n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3 -0.846278 -0.079514 -0.594889  0.480708 -0.034761 -0.165725  0.417818   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "     Enc_60  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3 -0.311721  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset='sii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', \n",
    "          'FGC-Season', 'BIA-Season', 'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "        \n",
    "train = update(train)\n",
    "test = update(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (2736, 119) || Test Shape : (20, 118)\n"
     ]
    }
   ],
   "source": [
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "for col in cat_c:\n",
    "    mapping_train = create_mapping(col, train)\n",
    "    mapping_test = create_mapping(col, test)\n",
    "    \n",
    "    train[col] = train[col].replace(mapping_train).astype(int)\n",
    "    test[col] = test[col].replace(mapping_test).astype(int)\n",
    "\n",
    "print(f'Train Shape : {train.shape} || Test Shape : {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    \n",
    "    df = df.drop(df[df['Physical-BMI'] == 0].index)\n",
    "    df = df.drop(df[df['Physical-Diastolic_BP'] == 0].index)\n",
    "    df = df.drop(df[df['Physical-Systolic_BP'] == 0].index)\n",
    "    df = df.drop(df[df['Physical-Diastolic_BP'] > 160].index)\n",
    "\n",
    "    children = df[df['Basic_Demos-Age'] <= 12]\n",
    "    df = df.drop(children[children['FGC-FGC_CU'] > 80].index)\n",
    "    df = df.drop(children[children['FGC-FGC_GSND'] > 80].index)\n",
    "\n",
    "    df = df.drop(df[df['BIA-BIA_BMI'] == 0].index)\n",
    "    df = df.drop(df[df['BIA-BIA_BMC'] > 1000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_BMR'] > 40000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_DEE'] > 60000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_ECW'] > 2000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_FFM'] > 2000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_ICW'] > 2000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_LDM'] > 2000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_LST'] > 2000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_SMM'] > 2000].index)\n",
    "    df = df.drop(df[df['BIA-BIA_TBW'] > 2000].index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    season_cols = [col for col in df.columns if 'Season' in col]\n",
    "    df = df.drop(season_cols, axis=1) \n",
    "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
    "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
    "    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n",
    "    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n",
    "    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n",
    "    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n",
    "    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n",
    "    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n",
    "    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n",
    "    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n",
    "    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n",
    "    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n",
    "    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n",
    "    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n",
    "    df['BMI_PHR'] = df['Physical-BMI'] * df['Physical-HeartRate']\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = remove_outliers(train)\n",
    "train = feature_engineering(train)\n",
    "test = feature_engineering(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>Physical-Diastolic_BP</th>\n",
       "      <th>Physical-HeartRate</th>\n",
       "      <th>Physical-Systolic_BP</th>\n",
       "      <th>Fitness_Endurance-Max_Stage</th>\n",
       "      <th>Fitness_Endurance-Time_Mins</th>\n",
       "      <th>Fitness_Endurance-Time_Sec</th>\n",
       "      <th>FGC-FGC_CU</th>\n",
       "      <th>FGC-FGC_CU_Zone</th>\n",
       "      <th>FGC-FGC_GSND</th>\n",
       "      <th>FGC-FGC_GSND_Zone</th>\n",
       "      <th>FGC-FGC_GSD</th>\n",
       "      <th>FGC-FGC_GSD_Zone</th>\n",
       "      <th>FGC-FGC_PU</th>\n",
       "      <th>FGC-FGC_PU_Zone</th>\n",
       "      <th>FGC-FGC_SRL</th>\n",
       "      <th>FGC-FGC_SRL_Zone</th>\n",
       "      <th>FGC-FGC_SRR</th>\n",
       "      <th>FGC-FGC_SRR_Zone</th>\n",
       "      <th>FGC-FGC_TL</th>\n",
       "      <th>FGC-FGC_TL_Zone</th>\n",
       "      <th>BIA-BIA_Activity_Level_num</th>\n",
       "      <th>BIA-BIA_BMC</th>\n",
       "      <th>BIA-BIA_BMI</th>\n",
       "      <th>BIA-BIA_BMR</th>\n",
       "      <th>BIA-BIA_DEE</th>\n",
       "      <th>BIA-BIA_ECW</th>\n",
       "      <th>BIA-BIA_FFM</th>\n",
       "      <th>BIA-BIA_FFMI</th>\n",
       "      <th>BIA-BIA_FMI</th>\n",
       "      <th>BIA-BIA_Fat</th>\n",
       "      <th>BIA-BIA_Frame_num</th>\n",
       "      <th>BIA-BIA_ICW</th>\n",
       "      <th>BIA-BIA_LDM</th>\n",
       "      <th>BIA-BIA_LST</th>\n",
       "      <th>BIA-BIA_SMM</th>\n",
       "      <th>BIA-BIA_TBW</th>\n",
       "      <th>PAQ_A-PAQ_A_Total</th>\n",
       "      <th>PAQ_C-PAQ_C_Total</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "      <th>Enc_1</th>\n",
       "      <th>Enc_2</th>\n",
       "      <th>Enc_3</th>\n",
       "      <th>Enc_4</th>\n",
       "      <th>Enc_5</th>\n",
       "      <th>Enc_6</th>\n",
       "      <th>Enc_7</th>\n",
       "      <th>Enc_8</th>\n",
       "      <th>Enc_9</th>\n",
       "      <th>Enc_10</th>\n",
       "      <th>Enc_11</th>\n",
       "      <th>Enc_12</th>\n",
       "      <th>Enc_13</th>\n",
       "      <th>Enc_14</th>\n",
       "      <th>Enc_15</th>\n",
       "      <th>Enc_16</th>\n",
       "      <th>Enc_17</th>\n",
       "      <th>Enc_18</th>\n",
       "      <th>Enc_19</th>\n",
       "      <th>Enc_20</th>\n",
       "      <th>Enc_21</th>\n",
       "      <th>Enc_22</th>\n",
       "      <th>Enc_23</th>\n",
       "      <th>Enc_24</th>\n",
       "      <th>Enc_25</th>\n",
       "      <th>Enc_26</th>\n",
       "      <th>Enc_27</th>\n",
       "      <th>Enc_28</th>\n",
       "      <th>Enc_29</th>\n",
       "      <th>Enc_30</th>\n",
       "      <th>Enc_31</th>\n",
       "      <th>Enc_32</th>\n",
       "      <th>Enc_33</th>\n",
       "      <th>Enc_34</th>\n",
       "      <th>Enc_35</th>\n",
       "      <th>Enc_36</th>\n",
       "      <th>Enc_37</th>\n",
       "      <th>Enc_38</th>\n",
       "      <th>Enc_39</th>\n",
       "      <th>Enc_40</th>\n",
       "      <th>Enc_41</th>\n",
       "      <th>Enc_42</th>\n",
       "      <th>Enc_43</th>\n",
       "      <th>Enc_44</th>\n",
       "      <th>Enc_45</th>\n",
       "      <th>Enc_46</th>\n",
       "      <th>Enc_47</th>\n",
       "      <th>Enc_48</th>\n",
       "      <th>Enc_49</th>\n",
       "      <th>Enc_50</th>\n",
       "      <th>Enc_51</th>\n",
       "      <th>Enc_52</th>\n",
       "      <th>Enc_53</th>\n",
       "      <th>Enc_54</th>\n",
       "      <th>Enc_55</th>\n",
       "      <th>Enc_56</th>\n",
       "      <th>Enc_57</th>\n",
       "      <th>Enc_58</th>\n",
       "      <th>Enc_59</th>\n",
       "      <th>Enc_60</th>\n",
       "      <th>BMI_Age</th>\n",
       "      <th>Internet_Hours_Age</th>\n",
       "      <th>BMI_Internet_Hours</th>\n",
       "      <th>BFP_BMI</th>\n",
       "      <th>FFMI_BFP</th>\n",
       "      <th>FMI_BFP</th>\n",
       "      <th>LST_TBW</th>\n",
       "      <th>BFP_BMR</th>\n",
       "      <th>BFP_DEE</th>\n",
       "      <th>BMR_Weight</th>\n",
       "      <th>DEE_Weight</th>\n",
       "      <th>SMM_Height</th>\n",
       "      <th>Muscle_to_Fat</th>\n",
       "      <th>Hydration_Status</th>\n",
       "      <th>ICW_TBW</th>\n",
       "      <th>BMI_PHR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Basic_Demos-Age, Basic_Demos-Sex, CGAS-CGAS_Score, Physical-BMI, Physical-Height, Physical-Weight, Physical-Waist_Circumference, Physical-Diastolic_BP, Physical-HeartRate, Physical-Systolic_BP, Fitness_Endurance-Max_Stage, Fitness_Endurance-Time_Mins, Fitness_Endurance-Time_Sec, FGC-FGC_CU, FGC-FGC_CU_Zone, FGC-FGC_GSND, FGC-FGC_GSND_Zone, FGC-FGC_GSD, FGC-FGC_GSD_Zone, FGC-FGC_PU, FGC-FGC_PU_Zone, FGC-FGC_SRL, FGC-FGC_SRL_Zone, FGC-FGC_SRR, FGC-FGC_SRR_Zone, FGC-FGC_TL, FGC-FGC_TL_Zone, BIA-BIA_Activity_Level_num, BIA-BIA_BMC, BIA-BIA_BMI, BIA-BIA_BMR, BIA-BIA_DEE, BIA-BIA_ECW, BIA-BIA_FFM, BIA-BIA_FFMI, BIA-BIA_FMI, BIA-BIA_Fat, BIA-BIA_Frame_num, BIA-BIA_ICW, BIA-BIA_LDM, BIA-BIA_LST, BIA-BIA_SMM, BIA-BIA_TBW, PAQ_A-PAQ_A_Total, PAQ_C-PAQ_C_Total, SDS-SDS_Total_Raw, SDS-SDS_Total_T, PreInt_EduHx-computerinternet_hoursday, sii, Enc_1, Enc_2, Enc_3, Enc_4, Enc_5, Enc_6, Enc_7, Enc_8, Enc_9, Enc_10, Enc_11, Enc_12, Enc_13, Enc_14, Enc_15, Enc_16, Enc_17, Enc_18, Enc_19, Enc_20, Enc_21, Enc_22, Enc_23, Enc_24, Enc_25, Enc_26, Enc_27, Enc_28, Enc_29, Enc_30, Enc_31, Enc_32, Enc_33, Enc_34, Enc_35, Enc_36, Enc_37, Enc_38, Enc_39, Enc_40, Enc_41, Enc_42, Enc_43, Enc_44, Enc_45, Enc_46, Enc_47, Enc_48, Enc_49, Enc_50, Enc_51, ...]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Physical-BMI'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainML(model_class, train_data, test_data):\n",
    "    X = train_data.drop(['sii'], axis=1)\n",
    "    y = train_data['sii']\n",
    "\n",
    "    # Clean invalid values\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X = X.fillna(X.median())\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "                                                                                                                                                                                                 = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Clean folds\n",
    "        X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(X_train.median())\n",
    "        X_val = X_val.replace([np.inf, -np.inf], np.nan).fillna(X_val.median())\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        # Metrics\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "\n",
    "        # Test predictions\n",
    "        test_preds[:, fold] = model.predict(test_data.replace([np.inf, -np.inf], np.nan).fillna(test_data.median()))\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    # Optimize threshold\n",
    "    KappaOPtimizer = minimize(evaluate_predictions, x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters for LightGBM\n",
    "LightGBM_Params = {\n",
    "    'learning_rate': 0.046,\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 478,\n",
    "    'min_data_in_leaf': 13,\n",
    "    'feature_fraction': 0.893,\n",
    "    'bagging_fraction': 0.784,\n",
    "    'bagging_freq': 4,\n",
    "    'lambda_l1': 10,  # Increased from 6.59\n",
    "    'lambda_l2': 0.01,  # Increased from 2.68e-06\n",
    "    'device': 'gpu' if torch.cuda.is_available() else 'cpu',    \n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1,  # Increased from 0.1\n",
    "    'reg_lambda': 5,  # Increased from 1\n",
    "    'random_state': SEED,\n",
    "    'tree_method': 'gpu_hist' if torch.cuda.is_available() else 'auto'\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'iterations': 200,\n",
    "    'random_seed': SEED,\n",
    "    'verbose': 0,\n",
    "    'l2_leaf_reg': 10,  # Increase this value\n",
    "    'task_type': 'GPU' if torch.cuda.is_available() else 'CPU'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "TabNet_Params = {\n",
    "    'n_d': 64,              # Width of the decision prediction layer\n",
    "    'n_a': 64,              # Width of the attention embedding for each step\n",
    "    'n_steps': 5,           # Number of steps in the architecture\n",
    "    'gamma': 1.5,           # Coefficient for feature selection regularization\n",
    "    'n_independent': 2,     # Number of independent GLU layer in each GLU block\n",
    "    'n_shared': 2,          # Number of shared GLU layer in each GLU block\n",
    "    'lambda_sparse': 1e-3,  # Sparsity regularization\n",
    "    'optimizer_fn': torch.optim.Adam,\n",
    "    'optimizer_params': dict(lr=1e-2, weight_decay=1e-4),\n",
    "    'mask_type': 'sparsemax',\n",
    "    'scheduler_params': dict(mode=\"min\", patience=10, min_lr=1e-5, factor=0.5),\n",
    "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    'verbose': 1,\n",
    "    'device_name': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightGBM = LGBMRegressor(**LightGBM_Params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "XGBoost = XGBRegressor(**XGB_Params)\n",
    "CatBoost = CatBoostRegressor(**CatBoost_Params)\n",
    "RandomForest = RandomForestRegressor(random_state=SEED)\n",
    "TabNet = TabNetWrapper(**TabNet_Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:12<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.8006\n",
      "Mean Validation QWK ---> 0.3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.465\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "train_sub1 = train.copy(deep=True)\n",
    "test_sub1 = test.copy(deep=True)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "numeric_cols = train_sub1.select_dtypes(include=['float64', 'int64']).columns\n",
    "train_sub1[numeric_cols] = imputer.fit_transform(train_sub1[numeric_cols])\n",
    "\n",
    "for col in train_sub1.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_sub1[col] = train_sub1[col].fillna(train_sub1[col].mode()[0])\n",
    "        test_sub1[col] = test_sub1[col].fillna(test_sub1[col].mode()[0])\n",
    "\n",
    "train_sub1 = train_sub1.dropna(thresh=0.8*len(train_sub1), axis=1)\n",
    "train_sub1 = feature_engineering(train_sub1)\n",
    "train_sub1 = remove_outliers(train_sub1)\n",
    "test_sub1 = feature_engineering(test_sub1)\n",
    "\n",
    "voting_model = VotingRegressor(estimators=[\n",
    "    ('LightGBM', LightGBM),\n",
    "    ('CatBoost', CatBoost),\n",
    "    ('XgBoost', XGBoost)\n",
    "])\n",
    "\n",
    "submission1, _ = TrainML(voting_model, train_sub1, test_sub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority voting completed and saved to 'Final_Submission.csv'\n"
     ]
    }
   ],
   "source": [
    "sub1 = submission1\n",
    "sub1 = sub1.sort_values(by='id').reset_index(drop=True)\n",
    "\n",
    "combined = pd.DataFrame({\n",
    "    'id': sub1['id'],\n",
    "    'sii_1': sub1['sii'],\n",
    "})\n",
    "\n",
    "def majority_vote(row):\n",
    "    return row.mode()[0]\n",
    "\n",
    "combined['final_sii'] = combined[['sii_1']].apply(majority_vote, axis=1)\n",
    "\n",
    "final_submission = combined[['id', 'final_sii']].rename(columns={'final_sii': 'sii'})\n",
    "\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Majority voting completed and saved to 'Final_Submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    0\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    0\n",
       "5   001f3379    0\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    0\n",
       "10  0087dd65    0\n",
       "11  00abe655    0\n",
       "12  00ae59c9    1\n",
       "13  00af6387    1\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
